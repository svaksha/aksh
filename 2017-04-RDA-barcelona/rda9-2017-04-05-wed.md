# IG Domain Repositories 

Meeting objectives
## 1. Introduction to domain protocols for RDM - Peter Doom (@danskaw) and Patrick Aerts

#### 3 takehome messages
+ treat data management and software sustainability on equal footing, atleast policy wise
    + no access to software after 10 yrs.
+ consider and treat data and software as value objects - starts making sense to keep value
+ make stakeholders position explicit, define their role.

##### stakeholders
1. gov, funding org
accountability, cultural herigate
+ general framework
2. science society
3. exec org 

#### one size DMP does not fit all : a domain oriented approach.
+ specialized solution addresses different sub disciplinies or communities
+ gets easier and better adoption and acceptance.
+ more suitable to adoption

#### organize communities
+ standards 
+ laws and regulations 
+ min conditions 
+ support resources
+ templates and examples
+ DDP - Domain Data Protocols must be openly published.
ex. protocols for biology, phy, chem, cog sci, etc..


#### DDP core idea

+ It will make researchers life easy by:
      + researcher can refer to data protocols
      + raise quality standards
      + diminish the admin burden for researchers
      + have a single approved model for RDM 
+ Makes it easier for funders
    + endorse community protocols for each domain
    

#### Advantages Framework and Protocols    
+ increases adoption via top-down approach.

#### Authorship of protocols: granularity

+ several ESFRI ERICs interested and want to work with them.
+ rely on existing work as much as possibke. Avoid starting from scratch.
+ Think modular - detail can vary.
   + generic protocol or model DMP will be helpful
   + Researchers will still deviate and wrie their owm DMP.
   + Within the margin of the framework the communities will decide on the detail
   

#### DDP Communities
+ 9 domains, 
+ humanities, 
2. humanities (archeology) 
3. Linguistics - CLARIN
4. 

#### Questions
+ do you consider the questions framed here is useful and 

2. general DCC DMP template:  https://dmponline.dcc.ac.uk
  

#### Reactions
+ several were already working in this direction
+ Activielf fits the plan.

#### Complications 
+ Question : difference between protocol, plan, template, guidelines and policy
  + protocol: formal status, recogniyzed and published.
  + plan: for individual project, not many.
  + template: empty frame for objects.
  + guidelines: help and reccommendations
  + policy: 


----

##  Jean-Claude Burgelman : Vision to action - from open to FAIR data

+ 10 years to become OA : 2008 to 2015 to 2017
+ Regulation for h2020
+ ORD pilot extension 

  + IPR, privacy and secutity
  + targeted towards data underlying publications
  + DMP is obligatory
  + costs to OA to resarch data fully eligible
  + project opt-out wont affect evaluatuon.
  Mantra: as open as possible , as closed as needed.
  
  
#### Opt- out reasons in proposals
+ IPR: above 50 %
+ Privacy: 
    65%stay in 
    opt out is 35%
    voluntars optin was 14%
Main reason for optiing out was for IPR, privacy and 'no data generated'

#### FAIR DMP in H2020 
+ not only accessiblity of data, not enough

+ findaböe , reusable , interoperaböle and reusable

### FAIR DMP
+ 1 DMP per project not per dataset
+ DMP is a living document
+ Standard DMP is light and flexible
+ Template DMP on FAIR is in the document


#### Initial DMP experiences
+  Data preservation, IPR and standards are not well developed in the dmponline
+ Good DMP examples:  http://dcc.ac.uk/resources/data-management-plans/guidance-examples

#### FAIR data = DNA of the EOSC.

----

## Martin Stokhof : ERC Open Access.

#### Strategy
+ ERC supports OA to published output of research, peer- reviewed articles, monographs
+ 

##### Monitoring developments
+ Figshare and Dryad (data repos) 
+ RDA
+ Knowledge exchange
+ ERC events and studies, workshops etc

#### ORD pilot
+ ORD pilot can opt out at any time, application, granting or during hte project
+ ORD pilot: mandatory dmp must provide 
  1. data set ref and name
  2. data set desc
  3. standards and metadata
  4, data sharing methodolgy
  5. curation and preservation metodolgy

### Advice
+ ERC WG on OA has guidelines
+ infra: trusted data repos+ data protocols , metadata
+ DMP examples
+ how to deal with issues of privacy and copyright
+ They have inventories for 3 domains : PE, life sciences and SH.

#### PE domain: 
    + large data: astronomy, high energy physics, geography, etc
    + other disciplines in this domain are in development.
2. Repoisitoriies
  + specialised 
  + CESSDA, non-commercial
  + commercial: figshare and Dryad , zenodo
3. Metadata
  + discipline specific metadata standards
  
+ NWO and DFG are wlso worrking on dmponline+ copy right and privacy

##### Lifesciences domain

challenges: 1. large diversity, PDB, UniProt, GeneBank, images size

Approach of OA WG: Gathering advice and joint workshop with EMBO

#### Summary
+ requiers awareness of differences between domains 
+ need to raise awareness about OA and ORD
+ need trained data scientists with award systems 
+ needs transparency

----

## Panel

#### 1. Franco, Archeology.  

+ Research data is also management data
+ Ex. A researcher wants precise information
+ Regulations and govt rules created difficulties
+ in Humanities has large repositry management.
+ need more focus on the institutional duties

#### 2. Sussana Sansone, biosharing.org
+ is there a DB, implementing standards and where to deposit ex, the metagenomics dataset
in biosharing, we interrelate the data sets
+ ELIXIR interoperability platform
+ work with data policy makers and researchers
+ EMBO Press has a data poicy
+ Working with the community and the adopters
+ Interoperability is costly.

#### 3. Ron Dekker, NL and director of CESSDA
+ Science must open up and learn to collaborate
+ Data is the new oil  - explain what your data is about
+ Platform revolution

+ Toomany stakeholders
+ Too many templates , different purposes 
+ Few tools, need more software tools to ensure reproducibility
+ DMP - static or dynamic, 
+ DMP framework: Social sciences need more proivacy
+ DMP - at the start of the project , between and at the end of the project, can be part of the DMP 

DMP @CESSDA
+ training and tools 

#### 4. Dieter , charir of commitee, CLARIN
+ Common Language Resources and Tech Infra
+ Research Infra for humanities  and Social sciences
+ ex. eye-tracking datasets 

CLARIN centers
+ distributed architechture, web application, web services
+ nodes and centres
+ B centers are more relevant

+ Overview of B-centers
+ CLARIN certiffication


+ No single DMP 
+ RI - dat preservation
+ automated checks for data
+ interoperability checks
+ Wizard for DMP 
+ DMP: http://de.clarin.eu/en/preparation/data-management-plan


#### 5. Ari Asmi, project co-ord Helsink, Environmental domain

+ protocols for data management are a probblem.
+ cant go back in time for data measuing - ex 1977 data
+ protocols methods and management 
+ work on the same problem as other domains but from a different perspective - define vocabularies and understnad the data 
+ specific data sets need special DMP , needs a layered approach


#### Comments: 
+ Too many DMPs : 
+ Difficulties in organising RDMP 
+ Question: Mentioned there are few tools and we need more software tools to ensure reproducibility - However many researchers still use proprietary tools for data analysis, ex MATLAB. How can we ensure analytical reproducibility in such a scenario?

----


# IG Education
+ Yuri_D did an introduction.
+ How to establish cooperation between projects in EU.
+ 2. Updates from spin-off groups 
   + teaching TDM skills 
   + accreditation and certification
   + RDM curriculum

## EOSC pilot - WP7 - skills and capabilities?

#### what is EOSC
+ joining RI and e-infra
+ defining policy and governence
+ science demonstrators can prove it works
+ tackling skills required

+ Postgrad edu delivers the needed skill sets
+ Others dont , they just teach to use tools.
+ Training does not scale in some of hte other ways that data scientists can demonstrate their work.

+ WP7 has a framework to inform strategy - for EOSC 

+ Researchers draw on Data scources and also sending out data to collaborate with other researcher that must be interoperable
+ EOSC pilot partners : DCC, KIT, LIBER, DANS, EGI
+ About EU data e-infra, funding not very global. 

#### FOSTER plus : implementation of open science in H2020
+ http://fosteropenscience.eu
+ 2-year project with 900,000 € to train the researchers nd educate them. 
+ 11 partners
+ building on previous work - facilitation open science training in European research - 2014-jul2016
+ 2000+ training materials with OS taxonomy with learning objectives for partners.

+ Training for RDM and Open Research data
+ developing intermediate and advanced level, 
+ 3 research comm: life science (elixir) 
+ Open Science toolkit has SWC (software carpentry, data mining)

#### GO FAIR and IFDS
could not attend. 

+ Global Open FAIR: Findable -Accessible -Interoperable - Reusable
+ IFDS : Internet of FAIR data and services
+ Task isnt for one project. Need collaboration between projects and initiatives. Meeting of CODATA held on 3feb2017.
+ barendmons will publish a book

#### EDISON services for Core data expert - capacity building and skills management.
+ Body of Knowledge 
+ capacity building and data science
+ Interesting slide showing how the training model works
+ Slide on DSP profiles 
+ Building a data science team - data steward is important role
+ IEEE and ACM will develop a curriculum

#### ##robin Rice , Uni of Edinburgh
+ MOOC is based on video lectures. 
+ RDMS MOOC contents : understand Research data , DMP, Working with data, sharing data, archiving data.
+ The drop out rate is very high.

__Questions__ : 
    1. In MOOC the content is not CC licensed. 
    2. Female professors are not keen on the additional work.
    3. geographic coverage can get fuzzy when a proxy (tor) is used.
    
#### Dr Brigit Schimdt : Data talinig points at the göttingen univ

+ eRA, http://www.eresearch.uni-goettingen.de

The goettingen library offers meetups and focusses on the OS topics : research data, publishing, and other activities
+ Outreach via grad school mailing lists
+ Work mode is quarterly meets - 
    - working with pythin notebooks , discussings 
    - hack hour hackyhour on the github, monthly.

+ ODD Open data day celebration on 1 mar 17
+ Will do a meetin on metrics etc..

#### Rob Quick: CODATA WG summer school on Research Data Science 
+ DataTrieste 2016
+ Curriculum: author carpentry, linux bash, 
data analysis in R, etc..
+ http://indico.ictp.it/event/7974/ to apply.
+ Train the trainers. 
+ __QUESTIONS__: How can the summer school content be shared with other universities. SWC by Dr. Greg Wilson

#### 2-min presentations 
1. Freya presented the Denver breakout group sessions : text and data mining, on Friday at 11:30AM.

2. Tim.
+ Go to Groups on the website to find the groups for participating as an IG. 
 

3. Uni of Cambridge - Data Champion Communities
+ 2 people supporting the training.
+ Created a community that worked as a champion of communities for data sharing. 
+ MR1 room at 1400 H on Thursday.

4. BoF on __RDM literacy__
+ Goal to create better conditions for including RDM courses.
+ Education is different from Training : what is not taught/educated cannot be trained.

#### Discussion
+ Simply saying FAIR isnt enough as a western concept, rather from a developing counrty perspective.
+ Cross-domain issues.
+ Carter Smith from OECD: digital skills, science policy groups. What are the needs, gaps, role of librarians, are some questions. Dont know the policies to take. Dont know the 500 new data stewards that have been created. Need a top-down approach. Specific issues about science must be linked with top-down policy. Policy needs are looked at in OECD. Need more than generic digital skills.
+ Sustainabiltity of knowledge and dissemination of the same.
+ Sharing knowledge as bottom-up is very important.

#### Send my questions to nora or Yuri.
+ Add the 4 points you spoke about. 

----

# IG Data Versioning 
+ Lesley Wyborn, National Computational Infrastructure, ANU (Australian National University.)

+ Introduction 
+ Standards for versioning

#### Why versioning is important
+ data are sourced from national/international repos (49 PB in AU)
+ many of the data sets are continually added, revised
+ Data are being copied between repos or to local sites
+ Colocation with HPC or cloud is easy to create a derived product

+ Seamless data sets with thousands of individual files
+ higher level data products are generated in short time frames

+ Some mature data centers offer webservices for: 
     + dynamic select of subsets based on user defined spatial data sets.
+ hard for researcher to cite data sets. 

We want :
    + agreed procedures for versioning data sets and data products
    + persistent identifieers to data sets
    + Ex. in an image, using versioning we must be able to say this pixel is from this data set and goes in this spot. This must be done on the fly.

#### Jens Klump : OCE science leader
+ data sets change over time.
+ data sets are updated on a scheduled basis., improvements are collected 

#### Build Vs Version
+ ver number are incremented sequentially

#### semantic versioning
+ sequence based identifieers
+ aestheric considerations
+ marketing considerations

##### Cersioning and identifiers
+ Force11 and DataCITE debate about persistent identiifiers


## Data versioning - Andreas

### identification of dynamic data
+ cite and identify the data as it existed in a specific point in time.
+ identify precisly the subsaet of the dynamic data used in a process.
+ DONT want a data dump (as zip file )

#### RDA WGDC - solution
+ we have data and access /queery the data
+ make the data time-stamped and versioned  - dont overwrite hte data , just mark it.
+ prepare a way to store the queries with a timestamp

2. Data citation
  + store the query with a timestamp
  + sasign a PID to the timestamped query (dynamically leading to data)
3. Access: Reuse query on versioned data according ti the tiimestamp.
4. Dynamic data citation

#### Versioning SQL data
1. Integrated : 
     + extend original tables by temporal metadata
     + expand primary key by record-versioning col. keep them in the master table but it will change the API so its not viable
2. Separated
    + utilize the history table
3. Hybrid: Only move any changes to an indexing table
4. solution depends on trade-off

They have a paper on it 

#### Versioning CSV
+ git based prototype for CSV files : using separat e folders and branches

+ MySQL prototype
Mercenary on github has a csv 

### for XML data 
+ had scalability issues
+ add tags in each xml branch when its inserted or deleted.
+ only add timestamp to the top of hte branch but that is slow.
+ Column store DB for IR models

### Loinked open data- no implementation yet
+ file based, github
+ RDBMS
+ LOD loinked open database - add time validity triples.
+ For High frequency operation, when a read operation is over it will not be read again. (IMPT)

WG is closed but they are helping others.
* https://rd-alliance.org/working-groups/data-citation-wg.html

## Robert Downs, CDAC, NASA
+ EODIS does not use a common Standard to number versions
+ Different data centers have different practices, Integrating data sets , no common standards
+ DAAC (distributed active archive centers)
+ number of Versions vary.
+ Provenance is tracked independent of a standard numbering scheme.
+ New DOIs are assigned as new versions are generated.

+ For multiple data changes in a day they have a range of dates, yyyy-mm-dd-timestamp-version1. 
+ Collections are versioned as well.

+ SEDAC guide to assigning global persitent identifiers.
+ SEDAC procedure for assigning GPI
   + DOI is assigned to datasets and documentation. Not for software yet.
   + EZID and datacite metadata schema.
   + DOI's are also recorded in the FGDC CSDGM
   + Related identifier field is used to link other data
   + DOI record is modified when location of landing page changes

+ Timestamps for meta studies is very important - keep the local timestamps for clean semantics (irrespective of labeling)   
   + with DB this can be tracked but with a file bsed systems this is a problem.

## Ari Asmi

Types of Versioning :
1. Understand hte versioning strategy.
2. every change (read/write) is a version strategy
3. Cited - that is a new version : temp DOI, then doi is given only when paper is cited.
4. Periodic
5. Significant change - only big changes matter. Small is ignored.
6. No versioning - good (no versioning) and bad (assign a doi but the doi only links to the changed data, not old data)

+ Versioning for Reproducibility 
  + users may be collaborators, not just scientists
  + citation credit part also needs versioning (IMPT, and Provenance is taking into account this problem.)

+ Key point is to make it explicit why versioning is being used.
+ Need guiding principles for data versioning

+ granularity : one DOI for a large dataset will cause confusion. 

+ How do you tie the SW versioning system for data stakeholders.
+ DCAT is used for most but it does not allow versioning.
+ Provenance Vs. table


